"""
HypoEvolve í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” hypoevolve_default.yaml ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬
í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ ìµœì í™” í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import os
import tempfile

from hypoevolve import HypoEvolve
from hypoevolve.core.config import Config


def main():
    """
    HypoEvolve í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    """
    print("ğŸš€ HypoEvolve ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("=" * 50)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
        print("   export OPENAI_API_KEY='your-api-key-here'")
        return

    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "configs/hypoevolve_default.yaml"
    print(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")

    try:
        config = Config.from_yaml(config_path)
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì‚¬ìš©
        config.api_key = api_key

        print("âœ… ì„¤ì • ë¡œë“œ ì„±ê³µ!")
        print(f"   - ëª¨ë¸: {config.model}")
        print(f"   - ìµœëŒ€ ë°˜ë³µ: {config.max_iterations}")
        print(f"   - ì¸êµ¬ í¬ê¸°: {config.population_size}")
        print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {config.output_dir}")
        print(f"   - ì˜¨ë„: {config.temperature}")
        print(f"   - ë³‘ë ¬ í‰ê°€: {config.parallel_evaluations}")
    except Exception as e:
        print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # HypoEvolve ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    hypoevolve = HypoEvolve(config)

    # ì´ˆê¸° ì½”ë“œ (ë¹„íš¨ìœ¨ì ì¸ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´)
    initial_code = """
def fibonacci(n):
    \"\"\"ë¹„íš¨ìœ¨ì ì¸ ì¬ê·€ í”¼ë³´ë‚˜ì¹˜ êµ¬í˜„\"\"\"
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    import sys
    n = int(input())
    result = fibonacci(n)
    print(result)
"""

    # ë¬¸ì œ ì„¤ëª…
    problem_description = """
í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìµœì í™”í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. ì…ë ¥: ì •ìˆ˜ n (0 <= n <= 20)
2. ì¶œë ¥: në²ˆì§¸ í”¼ë³´ë‚˜ì¹˜ ìˆ˜
3. ì„±ëŠ¥: ë¹ ë¥¸ ì‹¤í–‰ ì‹œê°„ (íŠ¹íˆ í° nì— ëŒ€í•´)
4. ì •í™•ì„±: ì˜¬ë°”ë¥¸ ê²°ê³¼ ì¶œë ¥

í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ...

í˜„ì¬ ì½”ë“œëŠ” ë¹„íš¨ìœ¨ì ì¸ ì¬ê·€ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ë™ì  í”„ë¡œê·¸ë˜ë°, ë©”ëª¨ì´ì œì´ì…˜, ë˜ëŠ” ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•´ì„œ ìµœì í™”í•´ë³´ì„¸ìš”.

ì„±ëŠ¥ ëª©í‘œ:
- n=10ì¼ ë•Œ 0.01ì´ˆ ì´ë‚´
- n=15ì¼ ë•Œ 0.1ì´ˆ ì´ë‚´  
- n=20ì¼ ë•Œ 0.5ì´ˆ ì´ë‚´
"""

    # í‰ê°€ í•¨ìˆ˜ ìƒì„±
    evaluation_code = """
import subprocess
import sys
import time
from typing import Dict, Any


def evaluate(program_path: str, context: Dict[str, Any]) -> Dict[str, Any]:
    \"\"\"í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ í‰ê°€\"\"\"
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (ì‘ì€ ê°’ë¶€í„° í° ê°’ê¹Œì§€)
    test_cases = [
        {"input": 0, "expected": 0, "weight": 1.0},
        {"input": 1, "expected": 1, "weight": 1.0},
        {"input": 2, "expected": 1, "weight": 1.0},
        {"input": 3, "expected": 2, "weight": 1.0},
        {"input": 5, "expected": 5, "weight": 1.2},
        {"input": 8, "expected": 21, "weight": 1.5},
        {"input": 10, "expected": 55, "weight": 2.0},
        {"input": 15, "expected": 610, "weight": 3.0},
        {"input": 20, "expected": 6765, "weight": 5.0},
    ]
    
    total_score = 0.0
    total_weight = sum(tc["weight"] for tc in test_cases)
    passed_tests = 0
    total_tests = len(test_cases)
    execution_times = []
    results = []
    
    for test_case in test_cases:
        try:
            start_time = time.time()
            
            # í”„ë¡œê·¸ë¨ ì‹¤í–‰
            process = subprocess.run(
                [sys.executable, program_path],
                input=str(test_case["input"]),
                capture_output=True,
                text=True,
                timeout=5  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            
            end_time = time.time()
            execution_time = end_time - start_time
            execution_times.append(execution_time)
            
            if process.returncode == 0:
                output = process.stdout.strip()
                expected = str(test_case["expected"])
                
                if output == expected:
                    passed_tests += 1
                    
                    # ê¸°ë³¸ ì ìˆ˜
                    base_score = test_case["weight"]
                    
                    # ì„±ëŠ¥ ë³´ë„ˆìŠ¤ (ë¹ ë¥¸ ì‹¤í–‰ì— ë³´ë„ˆìŠ¤)
                    if execution_time < 0.1:
                        time_bonus = base_score * 0.2
                    elif execution_time < 0.5:
                        time_bonus = base_score * 0.1
                    else:
                        time_bonus = 0
                    
                    total_score += base_score + time_bonus
                    results.append({
                        "input": test_case["input"],
                        "passed": True,
                        "time": execution_time,
                        "score": base_score + time_bonus
                    })
                else:
                    results.append({
                        "input": test_case["input"],
                        "passed": False,
                        "time": execution_time,
                        "score": 0,
                        "expected": expected,
                        "actual": output
                    })
            else:
                results.append({
                    "input": test_case["input"],
                    "passed": False,
                    "time": execution_time,
                    "score": 0,
                    "error": process.stderr.strip()
                })
                    
        except subprocess.TimeoutExpired:
            execution_times.append(5.0)
            results.append({
                "input": test_case["input"],
                "passed": False,
                "time": 5.0,
                "score": 0,
                "error": "Timeout"
            })
            continue
        except Exception as e:
            execution_times.append(5.0)
            results.append({
                "input": test_case["input"],
                "passed": False,
                "time": 5.0,
                "score": 0,
                "error": str(e)
            })
            continue
    
    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    normalized_score = total_score / total_weight if total_weight > 0 else 0.0
    accuracy = passed_tests / total_tests if total_tests > 0 else 0.0
    avg_time = sum(execution_times) / len(execution_times) if execution_times else 5.0
    
    # ì„±ëŠ¥ ì ìˆ˜ (ë¹ ë¥¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
    if avg_time < 0.1:
        performance_score = 1.0
    elif avg_time < 0.5:
        performance_score = 0.8
    elif avg_time < 1.0:
        performance_score = 0.6
    elif avg_time < 2.0:
        performance_score = 0.4
    else:
        performance_score = 0.2
    
    return {
        "score": min(normalized_score, 1.0),  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
        "accuracy": accuracy,
        "performance": performance_score,
        "passed_tests": passed_tests,
        "total_tests": total_tests,
        "avg_execution_time": avg_time,
        "test_results": results,
        "metrics": {
            "correctness": accuracy,
            "speed": performance_score,
            "efficiency": performance_score,
            "weighted_score": normalized_score
        }
    }
"""

    # ì„ì‹œ í‰ê°€ í•¨ìˆ˜ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
        f.write(evaluation_code)
        eval_file = f.name

    try:
        print("\nğŸ“Š í‰ê°€ í•¨ìˆ˜ ì„¤ì •...")
        hypoevolve.set_evaluation_function(eval_file, {"test_mode": True})
        print("âœ… í‰ê°€ í•¨ìˆ˜ ì„¤ì • ì™„ë£Œ!")

        print("\nğŸ§¬ ì§„í™” ì‹œì‘...")
        print(f"ì´ˆê¸° ì½”ë“œ ê¸¸ì´: {len(initial_code)} ë¬¸ì")
        print(f"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜: {config.max_iterations}")
        print(f"ì¸êµ¬ í¬ê¸°: {config.population_size}")
        print(f"ì—˜ë¦¬íŠ¸ ë¹„ìœ¨: {config.elite_ratio}")
        print(f"ë³€ì´ í™•ë¥ : {config.mutation_rate}")
        print()

        # ğŸ§¬ ì§„í™” ì‹¤í–‰
        best_program = hypoevolve.evolve(
            initial_code=initial_code,
            problem_description=problem_description,
            max_iterations=config.max_iterations,
        )

        print("\nğŸ‰ ì§„í™” ì™„ë£Œ!")
        print("=" * 50)

        if best_program:
            print("ğŸ† ìµœê³  ì„±ëŠ¥ í”„ë¡œê·¸ë¨:")
            print(f"   - ì ìˆ˜: {best_program.score:.4f}")
            print(f"   - ì„¸ëŒ€: {best_program.generation}")
            print(f"   - í”„ë¡œê·¸ë¨ ID: {best_program.id}")

            # ë©”íŠ¸ë¦­ ì •ë³´ ì¶œë ¥
            if hasattr(best_program, "metrics") and best_program.metrics:
                print(
                    f"   - ì •í™•ë„: {best_program.metrics.get('correctness', 'N/A'):.4f}"
                )
                print(f"   - ì„±ëŠ¥: {best_program.metrics.get('speed', 'N/A'):.4f}")
                print(
                    f"   - ê°€ì¤‘ ì ìˆ˜: {best_program.metrics.get('weighted_score', 'N/A'):.4f}"
                )

            print("\nğŸ“ˆ ìµœì í™”ëœ ì½”ë“œ:")
            print("-" * 50)
            print(best_program.code)
            print("-" * 50)

            # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
            stats = hypoevolve.database.stats()
            print("\nğŸ“Š ì§„í™” í†µê³„:")
            print(f"   - ì´ í”„ë¡œê·¸ë¨ ìˆ˜: {stats['size']}")
            print(f"   - í˜„ì¬ ì„¸ëŒ€: {stats['generation']}")
            print(f"   - ìµœê³  ì ìˆ˜: {stats['best_score']:.4f}")
            print(f"   - í‰ê·  ì ìˆ˜: {stats['avg_score']:.4f}")
            print(f"   - ìµœì € ì ìˆ˜: {stats['min_score']:.4f}")

            # MAP-Elites ì •ë³´ (ìˆëŠ” ê²½ìš°)
            if "coverage" in stats:
                print(f"   - ê·¸ë¦¬ë“œ ì»¤ë²„ë¦¬ì§€: {stats['coverage']:.2%}")
                print(
                    f"   - ì ìœ ëœ ì…€: {stats['occupied_cells']}/{stats['total_cells']}"
                )

            # ì§„í™” íˆìŠ¤í† ë¦¬ ì •ë³´
            try:
                history = hypoevolve.database.get_evolution_history()
                if history:
                    print("\nğŸ” ì§„í™” íˆìŠ¤í† ë¦¬:")
                    print(f"   - ì¶”ì ëœ ì„¸ëŒ€: {len(history.get('generations', []))}")
                    print(f"   - ê°œì„  ì¶”ì„¸: {history.get('trend', 'N/A')}")

                    # ìµœê·¼ ê°œì„  ì‚¬í•­ ì¶œë ¥
                    if "generations" in history and len(history["generations"]) > 0:
                        recent_gens = history["generations"][-5:]  # ìµœê·¼ 5ì„¸ëŒ€
                        print("   - ìµœê·¼ ì„¸ëŒ€ë³„ ìµœê³  ì ìˆ˜:")
                        for gen_data in recent_gens:
                            gen_num = gen_data.get("generation", "N/A")
                            best_score = gen_data.get("best_score", "N/A")
                            print(f"     * ì„¸ëŒ€ {gen_num}: {best_score:.4f}")

            except Exception as e:
                print(f"   - íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

        else:
            print("âŒ ì§„í™” ì‹¤íŒ¨ - ìµœì  í”„ë¡œê·¸ë¨ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì§„í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(eval_file):
            os.unlink(eval_file)
            print("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
